<!--
date: 2025-02-02T23:23:03.997Z
-->

Під час 
[https://www.youtube.com/watch?v=CvgfxH0UZa4](https://www.youtube.com/watch?v=CvgfxH0UZa4)
![YouTube Preview](https://img.youtube.com/vi/CvgfxH0UZa4/mqdefault.jpg)
 (з OpenAI) ми дізнаємося про CodeX - тоді нову редакцію великої мовної моделі, орієнтовану на генерацію коду. Це відбувалося 12 серпня 2021 року, на ранній стадії використання таких моделей для програмування, тому розмова сьогдні має історичну цінність. 

CodeX - нащадок GPT-3, але з численними покращеннями для кращого розуміння та генерації коду. Модель навчена на всьому тексті та відкритому коді в Інтернеті й може генерувати виконуваний код на основі природномовних підказок.

Грег підкреслює важливість забезпечення високої якості вхідних даних та цінностей під час навчання моделі, щоб запобігти упередженості та небажаній поведінці. Він також бачить потенціал CodeX у навчанні програмуванню, оскільки модель може надавати пояснення та керівництво у вигляді коду. Водночас, існують проблеми авторського права та доступу, які потрібно вирішити при розгортанні таких систем.
<!--
date: 2024-03-22T18:09:26
-->

[This video](https://www.youtube.com/watch?v=UaCzXLuEE1Y) 

![YouTube Preview](https://img.youtube.com/vi/UaCzXLuEE1Y/mqdefault.jpg)

 shows the use of [Tabby](https://github.com/TabbyML/tabby)  as a local replacement for GitHub Copilot for code autocompletion and function generation. The system will work **without the Internet. The code does not leave your computer.** 

The **StarCoder-3B**  model is used in **VSCode**. The installation and configuration of Tabby via Docker on a machine with an NVIDIA GeForce **RTX 3070**  GPU is considered.

    üõ† Installation and configuration of Tabby via Docker
    ‚öôÔ∏è Model selection (StarCoder, CodeLlama, DeepseekCoder)
    üí° Possibility to run Tabby on a machine with a GPU or CPU - what needs to be installed for CUDA to work

_The author believes that Tabby is more convenient to use than the ollama server._
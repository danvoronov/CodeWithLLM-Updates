<!--
date: 2024-03-25T17:46:13
-->

 [of plugins for VSCode local code generation -](https://www.youtube.com/watch?v=f0TzppYWvUQ)

![YouTube Preview](https://img.youtube.com/vi/f0TzppYWvUQ/mqdefault.jpg)

Continue [or](https://continue.dev/)Twinny [Options:
  🤖 Continue: everything is only through chat, lack of code autocompletion
  🦙 Llama Coder: code autocompletion, lack of chat interface
  🔍 Cody from Sourcegraph: unclear pricing model

  👯‍♂️](https://marketplace.visualstudio.com/items?itemName=rjmacarthy.twinny)Twinny**: a new project that 🤝 combines the functions of Llama Coder and Continue - chat and code autocompletion.**For autocompletion, so it doesn't freeze, you need to take a smaller "base" model (1-3B) and a more powerful computer._To make the chat work, you also need to raise the "instruct" model__._And I also added my mouse 😉
 
Since the launch of the
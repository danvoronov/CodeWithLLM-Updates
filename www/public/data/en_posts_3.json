[{"title":"2024-05-01 00:08","content":"\n\n<p>![Photo](2024-05-01-00-08-39.jpg)</p>\n\n<p>The screenshot shows the results of a \"blind\" comparison by people of two options for converting design into code: various available tools and a live person</p>\n<p>[</p>\n<p>JACoB (Just Another Coding Bot)](https://www.jacb.ai/)  - it looks like an AI assistant made under the influence of Devin, which converts designs into working code üíª, understands the repository üìÇ</p>\n\n<p>üîÑ Integrates with GitHub repositories and Figma designs</p>\n<p>ü§ù Smart dialogue with a person through review and code changes</p>\n<p>(will be) üîì Open source to extend functionality</p>\n<p>üë• Adapted to the workflow of an existing team</p>\n\n<p>Interestingly, similar to the new version of GitHub Copilot, they primarily focus on determining the list of <strong>tasks</strong>  for the AI agent by a human</p>\n\n<p><em>I couldn't check, on my GitHub account they write \"Try signing in with a different account.\"</em></p>","date":"2024-05-01T00:08:39","month":5},{"title":"2024-04-30 23:48","content":"\n\n<p><a href=\"https://github.blog/2024-04-29-github-copilot-workspace/\">https://github.blog/2024-04-29-github-copilot-workspace/</a><strong>GitHub introduces Copilot Workspace in TechPreview - a new AI-based development environment</strong> </p>\n\n<p>GitHub Copilot Workspace is an updated development environment where programmers can work with code in plain language üí¨. The system can help developers from the very beginning - planning the task ‚úÖ, writing specifications üìÑ, and generating code üíª.</p>\n<p>All this can be edited and refined ‚úèÔ∏è.</p>\n\n<p>The environment is integrated with GitHub Issues üì•, Pull Requests üîÉ, and repositories üóÉ.</p>\n\n<p>Developers can run and test code directly in Copilot Workspace üöÄ. This allows to simplify and speed up the entire software development cycle ‚è±.</p>\n\n<p>For professional developers, Copilot Workspace will allow more focus on system thinking üß† and move away from routine work that can be automated ‚öôÔ∏è.</p>","date":"2024-04-30T23:48:27","month":4},{"title":"2024-04-25 21:07","content":"\n\n\n<div style=\"text-align: center; margin: 20px 0;\"><iframe width=\"560\" height=\"315\" src=\"https://www.youtube-nocookie.com/embed/eR855VNPjhk\" title=\"YouTube video\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></div>\n\n\n\n<p>In <strong>Groq</strong>  on their YouTube channel, there is a demo of the project <a href=\"https://github.com/freuk/iter\">iter</a>  on the mixtral-8x7b-32768 model in the terminal on nix-shell. I have not tested it - his approach is to print everything and have minimal control over generation.</p>\n\n<p>1:53 But there is a cool feature, the command <strong>reflextion</strong>  - when the model will receive 6 requests with the instruction to think about the problem.</p>\n\n<p><em>The video is from March 8, and now there is also llama3-70b-8192 - but 8k versus 32k context window.</em> </p>\n\n<p>For VSCode in the extensions catalog, I found <a href=\"https://marketplace.visualstudio.com/items?itemName=Unclecode.groqopilot\">Groqopilot v0.0.81</a>, but now it is more likely not working than working.</p>","date":"2024-04-25T21:07:01","month":4},{"title":"2024-04-24 22:44","content":"\n\n\n<div style=\"text-align: center; margin: 20px 0;\"><iframe width=\"560\" height=\"315\" src=\"https://www.youtube-nocookie.com/embed/5poVsIeq3TM\" title=\"YouTube video\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></div>\n\n<p><strong>Snapdragon</strong>  presented X chips not for phones, but for Windows computers. In addition to the usual and graphics core, they will also have an NPU (neural processing unit). They promise that applications will work faster, and large language models (LLMs) can be run locally and natively without problems.</p>\n\n<p>VSCode at 17:53</p>\n<p>with <strong>Qualcomm AI Code Completion</strong> </p>\n<p>with llama-chat-v2-7b</p>","date":"2024-04-24T22:44:33","month":4},{"title":"2024-04-24 16:58","content":"\n\n<p><a href=\"https://ollama.com/library/phi3\">https://ollama.com/library/phi3</a><strong>A new version of the model from MS Phi-3 mini has been added to the ollama catalog.</strong> </p>\n\n<p>Despite its relatively small size of 3.8B, this model, according to the developers, demonstrates high efficiency in working with logic and mathematical tasks.</p>\n\n<p>During the training of Phi models, an approach similar to teaching children using \"textbook-like\" materials in mathematics, logic, and <strong>programming</strong>  was used. It is expected that this method will improve the overall results of the model in these areas.</p>\n\n<p><em>Also, an advantage of the new model is a version with a large context window - 128k tokens.</em></p>","date":"2024-04-24T16:58:22","month":4},{"title":"2024-04-24 13:26","content":"\n\n<p>A new player has emerged that aims to compete with OpenAI and Anthropic - the company <a href=\"https://www.reka.ai/\">Reka AI</a>.</p>\n\n<p>Currently, they have three models:</p>\n<p><strong>üüß Edge</strong>: a lightweight model with 7b parameters.</p>\n<p><strong>üüß Flash</strong>: a fast and powerful model with 21b parameters.</p>\n<p><strong>üüß Core</strong>: the largest and most powerful model for complex tasks (size unknown).</p>\n\n<p>In non-multimodal tests of code generation from text instructions, it seems that Core is inferior to GPT-4 and Claude-3-Opus.</p>","date":"2024-04-24T13:26:13","month":4},{"title":"2024-04-24 02:28","content":"\n\n\n<div style=\"text-align: center; margin: 20px 0;\"><iframe width=\"560\" height=\"315\" src=\"https://www.youtube-nocookie.com/embed/Smklr44N8QU\" title=\"YouTube video\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></div>\n\n\n\n<p>üÜï In the latest update of <a href=\"https://cursor.sh/\">Cursor</a>, Copilot++ has been improved and the \"Help\" section has been made in the form of an AI chat (currently in beta).</p>\n\n<p>This video review shows how Copilot++ can automatically generate code based on the context of the current project. The process of creating an interactive node graph in the Vue.js framework is demonstrated using hints and commands provided by Copilot++.</p>\n\n<p>The main features of Copilot++ demonstrated in the video:</p>\n\n<ol><li>Autocompletion of code on several <strong>lines</strong>  simultaneously.</li><li>Understanding the project context to provide relevant code suggestions.</li><li>Ability to <strong>add</strong>  documentation as reference materials for AI.</li><li>Flexible control of code generation through text instructions.</li></ol>\n\n<p>The video emphasizes that using AI assistants like Copilot++ allows developers to focus on high-level logic instead of writing individual lines of code. This can significantly increase productivity and remain relevant in the context of rapid technology development.</p>","date":"2024-04-24T02:28:17","month":4},{"title":"2024-04-19 14:30","content":"\n\n<p>I wrote it for you :)</p>\n\n<p><a href=\"https://danvoronov.medium.com/%D1%88%D1%96-%D0%B2-%D1%80%D0%BE%D0%B7%D1%80%D0%BE%D0%B1%D1%86%D1%96-%D0%BF%D0%B7-%D0%BF%D0%BE%D1%82%D0%BE%D1%87%D0%BD%D0%B8%D0%B9-%D1%81%D1%82%D0%B0%D0%BD-%D1%82%D0%B0-%D0%BF%D0%B5%D1%80%D1%81%D0%BF%D0%B5%D0%BA%D1%82%D0%B8%D0%B2%D0%B8-e93fdbb1997c\">AI in Software Development: Current State and Prospects</a></p>","date":"2024-04-19T14:30:44","month":4},{"title":"2024-04-18 23:45","content":"\n\n<p>ü•≥ Llama 3 is out!</p>\n\n<p>Models were trained on two newly announced clusters with specially built 24K GPUs on over 15T tokens of data - the training dataset is 7 times larger than that used for Llama 2,</p>\n<p>including <strong>4 times more code</strong>.</p>\n\n<p><a href=\"https://llama.meta.com/llama3/\">https://llama.meta.com/llama3/</a> </p>\n\n<p>models are also deployed on LPU <a href=\"https://groq.com/\">https://groq.com/</a></p>","date":"2024-04-18T23:45:16","month":4},{"title":"2024-04-18 15:40","content":"\n\n<p>Now to <a href=\"https://tabby.tabbyml.com/docs/models/\">the official registry</a>  Tabby added models of the CodeGemma series (2b and 7b) and CodeQwen (7b) for both completion and chat.</p>","date":"2024-04-18T15:40:29","month":4},{"title":"2024-04-13 20:59","content":"\n\n<p>![Photo](2024-04-13-20-59-58.jpg)</p>\n\n<p>A set of <strong>open</strong>  models from Google for writing code <a href=\"https://ai.google.dev/gemma/docs/codegemma\">CodeGemma</a>  added to <a href=\"https://ollama.com/library/codegemma:latest\">ollama</a>  (which is supported by Cody) and catalog.ngc.nvidia <a href=\"https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/codegemma<em>7b</em>base\">7B</a>  and <a href=\"https://catalog.ngc.nvidia.com/orgs/nvidia/teams/nemo/models/codegemma<em>2b</em>base\">2B</a>  - I did not find any full-fledged reviews and comparisons, perhaps, no one is interested in this.</p>\n\n<p>I also did not find in Google a direct indication of the size of the context window of these models.</p>","date":"2024-04-13T20:59:58","month":4},{"title":"2024-04-12 00:12","content":"\n\n<p><strong>Claude 3 is now available to all Cody users</strong>  üöÄ</p>\n<p>( <a href=\"https://sourcegraph.com/blog/claude-3-now-available-in-cody?utm<em>medium=email&amp;utm</em>content=302270481&amp;utm<em>source=hs</em>email\">blog</a> )</p>\n\n<p>Cody now supports the new Claude 3 family of models from Anthropic, which includes three models: Haiku (the fastest), Opus (the smartest), and Sonnet (intermediate).</p>\n\n<p>These models demonstrate improvements in code generation, the ability to quickly recall information from a large context, and other characteristics important for Cody.</p>\n\n<p>üÜì For Cody Free users, the <strong>Sonnet model (4th in the LMSYS Chatbot Arena rating) is now used by default</strong>, replacing Claude 2.0 (15th in the LMSYS Chatbot Arena rating).</p>\n\n<p>Cody <strong>Pro</strong>  users can choose between Haiku (8th in the LMSYS Chatbot Arena rating), Sonnet, and Opus (1st in the LMSYS Chatbot Arena rating)</p>","date":"2024-04-12T00:12:50","month":4},{"title":"2024-04-11 21:47","content":"\n\n<p>A video from VRSEN about the presentation of Devid - an AI software engineer. In it, the author demonstrates his open implementation of Devin, which has three main advantages: full access to the source code, training on real coding tasks, not just on GitHub Issues, and it is an agent system.</p>\n\n<p>The author shows how Devid creates a website with the game \"Game of Life\", modifying HTML, CSS, and JavaScript files. Then he demonstrates how to import Devid and other agents into his own project using Docker containers. The author also describes how to set up planner agents, developer agents, and browser agents so that they effectively collaborate to perform tasks.</p>\n\n<p>Finally, the author tests this agent system on a task of benchmarking several APIs, showing how agents can find <strong>documentation</strong>, execute code, and provide results.</p>\n\n<p>So far, everything works quite mediocrely, although he blames OpenAI for this. If the documentation has many pages, errors occur. It is also not mentioned how many tokens these tasks consumed, it is simply stated that it is more efficient than in Devin.</p>\n\n\n<div style=\"text-align: center; margin: 20px 0;\"><iframe width=\"560\" height=\"315\" src=\"https://www.youtube-nocookie.com/embed/BEpDRj9H3zE\" title=\"YouTube video\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></div>\n\n","date":"2024-04-11T21:47:06","month":4},{"title":"2024-04-11 21:19","content":"\n\n<p>![Photo](2024-04-11-21-19-35.jpg)</p>\n\n<p>At the <strong>Cloud Next</strong>  conference, Google showed its assistant for programming (on the slide it was a VSCode plugin) - the main emphasis was on the fact that Gemeni 1.5 has a context window that no competitor has - 1M tokens.</p>\n\n<p>Gemini Code Assist is available for testing for free until July 11, 2024.</p>","date":"2024-04-11T21:19:35","month":4},{"title":"2024-04-09 02:09","content":"\n\n<p>Video \"Why I stopped using Copilot\":</p>\n\n<p>    üß† If you don't practice skills, you can lose them. Using Copilot influenced the way I wrote code, prompting me to wait for AI hints instead of using my own brain.</p>\n\n<p>    üë®‚Äçüíª Writing code became less interesting. Copilot deprived me of the opportunity to learn, be creative, and solve problems on my own, which I enjoyed.</p>\n\n<p>    üîç The quality of Copilot's hints was unstable - often they were outdated or contained errors. I had to check the documentation, which reduced efficiency.</p>\n\n<p>    üîí Privacy is a big problem. Every time I used Copilot, fragments of my code were sent to a remote server, which is unacceptable to me as a supporter of privacy and self-hosting.</p>\n\n\n<div style=\"text-align: center; margin: 20px 0;\"><iframe width=\"560\" height=\"315\" src=\"https://www.youtube-nocookie.com/embed/Wap2tkgaT1Q\" title=\"YouTube video\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></div>\n\n\n<p>( a little clickbait and only one point of view )</p>","date":"2024-04-09T02:09:40","month":4},{"title":"2024-04-06 10:08","content":"\n\n<p>![Photo](2024-04-06-10-08-30.jpg)</p>\n\n<p>In <a href=\"https://www.phind.com/\">Phind</a>  there are now 5 (10 for users) free <strong>requests for 70b</strong>  per day. Previously, this option was for GPT-4.</p>\n\n<p>There is also a tab called 'ask a question about your code', marked as experimental, and there is no way to test it on the $10 plan, you need to upgrade to $20.</p>\n\n<p>I suspect this should connect the repository, but on the paid plans description page there are no details yet.</p>","date":"2024-04-06T10:08:30","month":4},{"title":"2024-04-05 21:14","content":"\n\n<p>![Photo](2024-04-05-21-14-37.jpg)</p>\n\n<p>Found a startup <a href=\"https://www.coze.com/\">Coze</a>  ‚Äî a significantly expanded clone of the functionality of <strong>GPTs</strong>, where</p>\n\n<p>1) there is no binding of the chat only to the OpenAI website - access to the bot is possible from Discord, Telegram, Slack (business bots), Facebook and Instagram Messenger, LINE (popular in Asia), Reddit (bots for specialized communities), Cici, Lark.</p>\n\n<p>2) it is possible to choose GPT 3.5, where the limit is 500 messages/day</p>\n\n<p>3) <a href=\"https://www.coze.com/store/plugin\">catalog of already configured plugins</a>  where there are GitHub, StackOverFlow, Code Interpreter, <a href=\"https://www.coze.com/store/plugin/7329367912139997186?from=explore_card\">Data Analysis</a> </p>\n\n<p>4) multi-agent mode - explanation in the video </p>\n<div style=\"text-align: center; margin: 20px 0;\"><iframe width=\"560\" height=\"315\" src=\"https://www.youtube-nocookie.com/embed/l00ZB2ZaVO0\" title=\"YouTube video\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></div>\n\n\n\n<p>‚å®Ô∏è In the <a href=\"https://www.coze.com/store/bot\">bot store</a>  I found <a href=\"https://www.coze.com/store/bot/7332362537742368774?panel=1&amp;bid=MDQEENGG04PIlXcm7-Pk2tsfKnYEHtKSJKKhfh0M7ZjrGvYRCAnokBXsyKyP8POPcX3bTQQA&amp;share=1&amp;from=others\">Code Companion from icheQ</a>  - now 11.7K users. There is also access to it from telegram <em>Minus - this is a startup now without a financial model.</em><em>Access only from the USA, the telegram bot answered me after 3 minutes and in general everything works very slowly.</em><em>Limits</em><em>GPT-4 100-50 messages/day.</em> </p>\n\n<p>chat chaos <a href=\"https://t.me/+m7bX9D4WjV4yMzgx\">https://t.me/+m7bX9D4WjV4yMzgx</a></p>","date":"2024-04-05T21:14:37","month":4},{"title":"2024-04-04 01:24","content":"\n\n<p>Google <a href=\"https://www.youtube.com/playlist?list=PLOU2XLYxmsIL8TxLOcsVI_hCq0c6cO-WQ\">released a video </a> from their <strong>Gemma Developer Day 2024</strong>.</p>\n\n<p>Gemma are open LLMs that can be used locally.</p>","date":"2024-04-04T01:24:24","month":4},{"title":"2024-04-02 22:09","content":"\n\n\n<div style=\"text-align: center; margin: 20px 0;\"><iframe width=\"560\" height=\"315\" src=\"https://www.youtube-nocookie.com/embed/zzw2OSFw9xI\" title=\"YouTube video\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></div>\n\n<p><a href=\"https://bito.ai/\">Bito</a>  is the most similar product to Github Copilot, but with a limited free plan (100 additions per month, 20 chat messages per day).</p>\n\n<p>ü§ñ The video is about the new Bito AI <a href=\"https://bito.ai/ai-code-review-agent/\">Code Review Agent</a>, which helps to reduce time on code review by 50% and improve code quality (works only in the $15/month plan, but there is a trial).</p>\n\n<p>üîß The agent integrates with GitHub and GitLab, automatically performs static code analysis, checks for vulnerabilities, and provides detailed comments with recommendations for code improvement.</p>","date":"2024-04-02T22:09:17","month":4},{"title":"2024-04-02 02:39","content":"\n\n<p>In the chats section on <a href=\"https://chat.lmsys.org/?arena\">Chatbot Arena</a>  and in <a href=\"https://labs.perplexity.ai/\">Perplexity playground</a>  appeared <strong>dbrx-instruct</strong>  model (<a href=\"https://github.com/databricks/dbrx\">github</a> ). I conducted a series of tests with code generation, and indeed the results are worthy. In addition, it is <strong>faster than CodeLLaMA</strong> -70B.</p>\n\n<p><em>The developer of the VSCode plugin</em> <a href=\"https://docs.double.bot/models\">Double</a><em>added to GPT-4 Turbo and Claude 3 (Opus) also DBRX Instruct, although it is not very clear why and also opened a GPT-5 waitlist.</em> </p>\n\n<p>DataBricks, a company known for its data processing and analysis solutions, has released one of the most powerful and efficient <strong>open</strong>  LLMs - DBRX. On the graphs that are published <a href=\"https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm\">in the presentation post</a>, the DBRX model outperforms other open solutions in the fields of mathematics and <strong>programming</strong>.</p>\n\n<p>This <strong>MoE 16x12B</strong>  multi-expert model (132 billion total parameters - 36 billion active parameters for processing each token), which in many tasks outperforms the open Grok-1 and the closed GPT-3.5 Turbo (but not Claude 3 Haiku). Context window 32k, tokenizer like GPT-4. Knowledge cutoff - December 2023.</p>\n\n<p>They say that according to tests, they outperform CodeLLaMA-70B. The DBRX model is quite large in size so that not everyone can run it, but not as huge as Grok-1, which practically no one can deploy at home now. Meta plans to release Lllama 3 sometime in July.</p>\n\n<p>The chat is also available at <a href=\"https://huggingface.co/spaces/databricks/dbrx-instruct\">https://huggingface.co/spaces/databricks/dbrx-instruct</a> </p>\n<p>(5-shoot max)</p>","date":"2024-04-02T02:39:17","month":4},{"title":"2024-03-29 20:36","content":"\n\n<p>In 13 minutes, prof. Andrew Ng (he has many courses on AI) demonstrates on slides advanced methods for using large language models to improve the software development process.</p>\n\n<p>The main ideas of the speech:</p>\n\n<p>üß† Agent approaches in AI are becoming increasingly popular and effective. This is an <strong>iterative</strong>  process where AI can learn, review, and improve its result.</p>\n\n<p>‚úçÔ∏è <strong>Reflection</strong>: An AI agent can evaluate its own code/result and refine it. This increases productivity.</p>\n\n<p>ü§ñ Multi-agent systems: using <strong>two or more agents</strong>, such as an expert coder and an expert reviewer, significantly improves the quality.</p>\n\n<p>üîß Using <strong>tools</strong>: connecting AI to various tools (web search, data analysis, etc.) expands its capabilities.</p>\n\n<p>üë∑‚Äç‚ôÇÔ∏è <strong>Planning</strong>: AI agents can autonomously plan actions and change the plan in case of failures, which is impressive.</p>\n\n<p>üîÄ <strong>Combination</strong>  of all these approaches opens up new possibilities and improves AI results compared to simple code generation (there is a slide with a graph, but with a 40% axis).</p>\n\n\n<div style=\"text-align: center; margin: 20px 0;\"><iframe width=\"560\" height=\"315\" src=\"https://www.youtube-nocookie.com/embed/sal78ACtGTc\" title=\"YouTube video\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe></div>\n\n<p><em>That is, agent-based artificial intelligence technologies may be the next step in the field of software development.</em></p>","date":"2024-03-29T20:36:42","month":3},{"title":"2024-03-28 11:54","content":"\n\n<p>Stability AI presented, and olllama added to the repository the <strong>instruct</strong>  version of their code generation model <strong>Stable Code</strong>. The model has a size of 3b and the quality of generation is at the expected level</p>\n\n<p><a href=\"https://ollama.com/library/stable-code\">https://ollama.com/library/stable-code</a></p>","date":"2024-03-28T11:54:16","month":3},{"title":"2024-03-28 02:58","content":"\n\n<p>![Photo](2024-03-28-02-58-33.jpg)</p>\n\n<p>And I also joined this with my mouse üòâ</p>\n\n<p>Since the launch of the <a href=\"https://chat.lmsys.org/?arena\">Chatbot Arena</a>  project, the <strong>GPT-4</strong>  model has always been in first place. (<a href=\"https://arstechnica.com/information-technology/2024/03/the-king-is-dead-claude-3-surpasses-gpt-4-on-chatbot-arena-for-the-first-time/\">news</a> )</p>\n\n<p>It is interesting that if at the beginning the GPT-3.5 model was impressive, now in comparison with new models it looks very weak and gives poor results. <em>We expect some change from the OpenAI company in the near future.</em></p>","date":"2024-03-28T02:58:33","month":3},{"title":"2024-03-25 17:46","content":"\n\n<p><a href=\"https://www.youtube.com/watch?v=f0TzppYWvUQ\">Video comparison</a> </p>\n\n<p><img src=\"https://img.youtube.com/vi/f0TzppYWvUQ/mqdefault.jpg\" alt=\"YouTube Preview\" /></p>\n\n<p> of VSCode plugins for local code generation - <a href=\"https://continue.dev/\">Continue</a>  or <a href=\"https://marketplace.visualstudio.com/items?itemName=rjmacarthy.twinny\">Twinny</a> </p>\n\n<p>Options:</p>\n<p>  ü§ñ Continue: everything is only through chat, no code autocompletion</p>\n<p>  ü¶ô Llama Coder: code autocompletion, no chat interface</p>\n<p>  üîç Cody from Sourcegraph: pricing model is unclear</p>\n\n<p>  üëØ‚Äç‚ôÇÔ∏è <strong>Twinny</strong>: a new project that ü§ù combines the features of Llama Coder and Continue - chat and code autocompletion.</p>\n\n<p><em>For autocompletion, so that it does not hang, of course, you need to take a smaller \"base\" model (1-3B) and a more powerful computer.</em><em>For the chat to work, you also need to run the \"instruct\" model</em>.</p>","date":"2024-03-25T17:46:13","month":3},{"title":"2024-03-24 15:59","content":"\n\n<p>Made a <a href=\"https://youtu.be/xwjA6CyZy_o\">video review of Codeium </a> </p>\n\n<p><img src=\"https://img.youtube.com/vi/xwjA6CyZy_o/mqdefault.jpg\" alt=\"YouTube Preview\" /></p>\n\n<p><a href=\"https://codeium.com/\">https://codeium.com/</a> </p>\n\n<p>when compared with Cursor and Phind, the system is not interesting and it is not clear why it has so many likes</p>","date":"2024-03-24T15:59:41","month":3},{"title":"2024-03-22 18:09","content":"\n\n<p><a href=\"https://www.youtube.com/watch?v=UaCzXLuEE1Y\">This video</a> </p>\n\n<p><img src=\"https://img.youtube.com/vi/UaCzXLuEE1Y/mqdefault.jpg\" alt=\"YouTube Preview\" /></p>\n\n<p> shows the use of <a href=\"https://github.com/TabbyML/tabby\">Tabby</a>  as a local replacement for GitHub Copilot for code autocompletion and function generation. The system will work <strong>without the Internet. The code does not leave your computer.</strong> </p>\n\n<p>The <strong>StarCoder-3B</strong>  model is used in <strong>VSCode</strong>. The installation and configuration of Tabby via Docker on a machine with an NVIDIA GeForce <strong>RTX 3070</strong>  GPU is considered.</p>\n\n<p>    üõ† Installation and configuration of Tabby via Docker</p>\n<p>    ‚öôÔ∏è Model selection (StarCoder, CodeLlama, DeepseekCoder)</p>\n<p>    üí° Possibility to run Tabby on a machine with a GPU or CPU - what needs to be installed for CUDA to work</p>\n\n<p><em>The author believes that Tabby is more convenient to use than the ollama server.</em></p>","date":"2024-03-22T18:09:26","month":3},{"title":"2024-03-21 00:30","content":"\n\n<p>The author of the VS Code extension <strong>Double</strong>  says that he was motivated by two years of observing how the GitHub Copilot team did not fix <a href=\"https://docs.double.bot/copilot\">user interface flaws</a>:</p>\n<ul><li>incorrect closing of brackets,</li><li>poor comment autocompletion,</li><li>lack of auto-import of libraries,</li><li>incomplete operation of the multi-cursor mode,</li></ul>\n<p>and all other problems of the outdated GPT-3.5 model (because GPT-4 is used where the system decides).</p>\n\n<p>The latest version of Double integrates the <strong>Claude 3 Opus model</strong>  from Anthropic, which, according to some benchmarks, surpasses GPT-4. <em>In addition to Opus, GPT-4 Turbo is also present.</em> [Double.bot](Double.bot)  was accepted into the Y Combinator accelerator. 50 requests to any of these models per month are available for free. A full subscription costs $20 (and GitHub Copilot now costs $10 without slash commands, $19 with them).</p>\n\n<p><em>The extension is not on</em> [open-vsx.org](open-vsx.org)<em>.</em> </p>\n<p>To register, you need to enter the code from the SMS - it never came to my Ukrainian number.</p>","date":"2024-03-21T00:30:06","month":3},{"title":"2024-03-20 02:29","content":"\n\n<p><a href=\"https://www.youtube.com/watch?v=bxU937z9GQE\">The response of the person who creates WebGPT</a> </p>\n\n<p><img src=\"https://img.youtube.com/vi/bxU937z9GQE/mqdefault.jpg\" alt=\"YouTube Preview\" /></p>\n\n<p> to the fact that his cool code generation system is not noticed because it is part of the ChatGPT Plus subscription - he shows it and you can pause to see how he makes web requests.</p>\n\n<p><em>In the end, he will make his own platform, which will look just like a chat.</em></p>","date":"2024-03-20T02:29:10","month":3},{"title":"2024-03-17 21:12","content":"\n\n<p>![Photo](2024-03-17-21-12-21.jpg)</p>\n\n","date":"2024-03-17T21:12:21","month":3},{"title":"2024-03-16 15:31","content":"\n\n<p>![Photo](2024-03-16-15-31-03.jpg)</p>\n\n<p><a href=\"https://www.codium.ai/products/alpha-codium\">AlphaCodium</a><strong>from CodiumAI</strong> </p>\n\n<p>CodiumAI, unlike other artificial intelligence systems for working with code, chose and occupied a narrow <strong>niche</strong>  - improving code quality (test generation, security and performance analysis).</p>\n\n<p>Now their next step is the AlphaCodium system, which can <em>automatically</em>  check the quality of the generated code. In this way, it is similar to how GANs work. It is <a href=\"https://github.com/Codium-ai/AlphaCodium\">open-source</a>  on the OpenAI API key, and solves problems formulated in the <a href=\"https://huggingface.co/datasets/deepmind/code_contests\">CodeContest</a>  format JSON.</p>\n\n<p><a href=\"https://www.youtube.com/watch?v=AOqnJLBYon4\">video explanation</a> </p>\n\n<p><img src=\"https://img.youtube.com/vi/AOqnJLBYon4/mqdefault.jpg\" alt=\"YouTube Preview\" /></p>\n\n<p> / <a href=\"https://www.codium.ai/blog/alphacodium-state-of-the-art-code-generation-for-code-contests/\">blog post</a> </p>\n<p>From ‚ÄúPrompt Engineering‚Äù to \"Flow Engineering‚Äù</p>","date":"2024-03-16T15:31:03","month":3}]